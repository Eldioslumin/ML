{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WhpMgiS1o5A"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The goal of this lab is to introduce you to data preprocessing techniques in order to make your data suitable for applying a learning algorithm.\n",
        "\n",
        "## 1. Handling Missing Values\n",
        "\n",
        "A common (and very unfortunate) data property is the ocurrence of missing and erroneous values in multiple features in datasets. For this exercise we will be using a data set about abalone snails.\n",
        "The data set is contained in the Zip file you downloaded from Moodle (abalone.csv).\n",
        "\n",
        "To determine the age of a abalone snail you have to kill the snail and count the annual\n",
        "rings. You are told to estimate the age of a snail on the basis of the following attributes:\n",
        "1. type: male (0), female (1) and infant (2)\n",
        "2. length in mm\n",
        "3. width in mm\n",
        "4. height in mm\n",
        "5. total weight in grams\n",
        "6. weight of the meat in grams\n",
        "7. drained weight in grams\n",
        "8. weight of the shell in grams\n",
        "9. number of annual rings (number of rings +1, 5 yields age)\n",
        "\n",
        "However, the data is incomplete. Missing values are marked with −1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aTRoZnye1o5D",
        "outputId": "3b2669b0-1ea1-46d6-b768-638722442986",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>length</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>total_weight</th>\n",
              "      <th>meat_weight</th>\n",
              "      <th>drained_weight</th>\n",
              "      <th>shell_weight</th>\n",
              "      <th>num_rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.070</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.210</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.155</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.055</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.3515</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.120</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
              "0     0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
              "1     1   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
              "2     0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
              "3     2  -1.000  0.255   0.080        0.2050       0.0895          0.0395   \n",
              "4     2   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
              "\n",
              "   shell_weight  num_rings  \n",
              "0         0.070         -1  \n",
              "1         0.210          9  \n",
              "2         0.155         10  \n",
              "3         0.055          7  \n",
              "4         0.120          8  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# load data \n",
        "df = pd.read_csv(\"abalone.csv\") #Should this not work please use the csv that was part of the zip file.\n",
        "df.columns=['type','length','width','height','total_weight','meat_weight','drained_weight','shell_weight','num_rings']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_KMa47j1o5E"
      },
      "source": [
        "### Exercise 1.1\n",
        "\n",
        "Compute the mean of of each numeric column and the counts of each categorical column, excluding the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-dCq2-NW1o5F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type              0.953534\n",
            "length            0.523692\n",
            "width             0.407955\n",
            "height            0.139610\n",
            "total_weight      0.828843\n",
            "meat_weight       0.359263\n",
            "drained_weight    0.180249\n",
            "shell_weight      0.238604\n",
            "num_rings         9.921756\n",
            "dtype: float64\n",
            "type              4089\n",
            "length            4052\n",
            "width             4052\n",
            "height            4052\n",
            "total_weight      4070\n",
            "meat_weight       4051\n",
            "drained_weight    4067\n",
            "shell_weight      4074\n",
            "num_rings         4077\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>length</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>total_weight</th>\n",
              "      <th>meat_weight</th>\n",
              "      <th>drained_weight</th>\n",
              "      <th>shell_weight</th>\n",
              "      <th>num_rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.3515</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.1200</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4171</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.2605</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.9485</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.3765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4176 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
              "0      0.0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
              "1      1.0   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
              "2      0.0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
              "3      2.0     NaN  0.255   0.080        0.2050       0.0895          0.0395   \n",
              "4      2.0   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
              "...    ...     ...    ...     ...           ...          ...             ...   \n",
              "4171   1.0   0.565  0.450   0.165        0.8870       0.3700          0.2390   \n",
              "4172   0.0   0.590  0.440   0.135        0.9660       0.4390          0.2145   \n",
              "4173   0.0   0.600  0.475   0.205        1.1760       0.5255          0.2875   \n",
              "4174   1.0   0.625  0.485   0.150           NaN       0.5310          0.2610   \n",
              "4175   0.0   0.710  0.555   0.195        1.9485       0.9455          0.3765   \n",
              "\n",
              "      shell_weight  num_rings  \n",
              "0           0.0700        NaN  \n",
              "1           0.2100        9.0  \n",
              "2           0.1550       10.0  \n",
              "3           0.0550        7.0  \n",
              "4           0.1200        8.0  \n",
              "...            ...        ...  \n",
              "4171        0.2490       11.0  \n",
              "4172        0.2605       10.0  \n",
              "4173        0.3080        9.0  \n",
              "4174        0.2960       10.0  \n",
              "4175        0.4950       12.0  \n",
              "\n",
              "[4176 rows x 9 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##################\n",
        "\n",
        "data_nomissing = df[df[df.columns]!= -1]\n",
        "# missing values become Nan\n",
        "\n",
        "mean = data_nomissing.mean()\n",
        "count = data_nomissing.count()\n",
        "\n",
        "print(mean)\n",
        "print(count)\n",
        "\n",
        "data_nomissing\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I0CjV2c1o5G"
      },
      "source": [
        "### Exercise 1.2\n",
        "\n",
        "Compute the median of each numeric column,  excluding the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sw_28SAt1o5G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type              1.00000\n",
            "length            0.54500\n",
            "width             0.42500\n",
            "height            0.14000\n",
            "total_weight      0.80175\n",
            "meat_weight       0.33600\n",
            "drained_weight    0.17050\n",
            "shell_weight      0.23350\n",
            "num_rings         9.00000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "##################\n",
        "median = data_nomissing.median()\n",
        "print(median)\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMltOlp_1o5G"
      },
      "source": [
        "### Exercise 1.3\n",
        "\n",
        "Handle the missing values in a way that you find suitable. Think about different ways. Discuss dis-/advantages of your approach. Argue your choices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First I kind of need to look at my data, how many missing values do I have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows with at least one -1 value: 905\n"
          ]
        }
      ],
      "source": [
        "rows_with_minus_one = df.apply(lambda row: (-1 in row.values), axis=1).sum()\n",
        "print(\"Number of rows with at least one -1 value:\", rows_with_minus_one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So apparently this is 905 elements with a missing value out of 4167 examples. Seem too many to delete/ignore those instances.\n",
        "Is there any data in particular that is missing more than the others? Is there any relationship between these missing values?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type               87\n",
            "length            124\n",
            "width             124\n",
            "height            124\n",
            "total_weight      106\n",
            "meat_weight       125\n",
            "drained_weight    109\n",
            "shell_weight      102\n",
            "num_rings          99\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "minus_one_counts = (df == -1).sum()\n",
        "print(minus_one_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Indices of rows with more than three missing values:\n",
            "Index([], dtype='int64')\n",
            "\n",
            "Count of missing values in each of these rows:\n",
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "# Count missing values in each column\n",
        "missing_counts_rows = data_nomissing.isna().sum(axis=1)\n",
        "\n",
        "# Filter rows with more than three missing values\n",
        "rows_with_many_missing = missing_counts_rows[missing_counts_rows > 3]\n",
        "\n",
        "print(\"Indices of rows with more than three missing values:\")\n",
        "print(rows_with_many_missing.index)\n",
        "\n",
        "print(\"\\nCount of missing values in each of these rows:\")\n",
        "print(rows_with_many_missing)   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So no any one piece of data is particularly as missing as the others. (We could further resarch into missing data by checking if there is any relationship between missing data all together)\n",
        "\n",
        "Checking again our data, we don't really see any pattern about why data could be missing (meaning, our data is very likely not systematically missing, like in a form where single people don't need to fill when they got married or leave the square blank). Snails also don't have the best privacy laws, so data aggregation cannot explain this missing information either.\n",
        "\n",
        "1. type: male (0), female (1) and infant (2)\n",
        "2. length in mm\n",
        "3. width in mm\n",
        "4. height in mm\n",
        "5. total weight in grams\n",
        "6. weight of the meat in grams\n",
        "7. drained weight in grams\n",
        "8. weight of the shell in grams\n",
        "9. number of annual rings (number of rings +1, 5 yields age)\n",
        "\n",
        "Similarly, because our study objects are nails, what would be the purpose of finding a relationship between missing length in mm and width in mm?\n",
        "As in, any one missing information was more likely related to a mistake/omission by the scientist measuring the snails. \n",
        "We could be interested in seeing if any one source of our data often missed some metric, and then trying to understan why (was the scientist lazy, or was this simply not a metric that was registered when they were working?) But this would be far more relevant on data for a real experiment than for our study case.\n",
        "\n",
        "But an alternative could be to calculate the mean and just insert that to the missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gxDCHrb31o5G"
      },
      "outputs": [],
      "source": [
        "##################\n",
        "#INSERT CODE HERE#\n",
        "# \n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpklBouL1o5H"
      },
      "source": [
        "### Exercise 1.4\n",
        "\n",
        "Perform Z-score normalization on every column (except the type of course!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HbkY--hk1o5I"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>length</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>total_weight</th>\n",
              "      <th>meat_weight</th>\n",
              "      <th>drained_weight</th>\n",
              "      <th>shell_weight</th>\n",
              "      <th>num_rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.443993</td>\n",
              "      <td>-1.439534</td>\n",
              "      <td>-1.189003</td>\n",
              "      <td>-1.232135</td>\n",
              "      <td>-1.166955</td>\n",
              "      <td>-1.205076</td>\n",
              "      <td>-1.211842</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.052442</td>\n",
              "      <td>0.121288</td>\n",
              "      <td>-0.110489</td>\n",
              "      <td>-0.310090</td>\n",
              "      <td>-0.461650</td>\n",
              "      <td>-0.354425</td>\n",
              "      <td>-0.205594</td>\n",
              "      <td>-0.285597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.695776</td>\n",
              "      <td>-0.432552</td>\n",
              "      <td>-0.350159</td>\n",
              "      <td>-0.638881</td>\n",
              "      <td>-0.645838</td>\n",
              "      <td>-0.605962</td>\n",
              "      <td>-0.600906</td>\n",
              "      <td>0.024243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.540232</td>\n",
              "      <td>-1.428673</td>\n",
              "      <td>-1.273999</td>\n",
              "      <td>-1.211879</td>\n",
              "      <td>-1.287397</td>\n",
              "      <td>-1.319655</td>\n",
              "      <td>-0.905276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.820479</td>\n",
              "      <td>-1.087090</td>\n",
              "      <td>-1.069168</td>\n",
              "      <td>-0.974820</td>\n",
              "      <td>-0.980521</td>\n",
              "      <td>-0.939820</td>\n",
              "      <td>-0.852468</td>\n",
              "      <td>-0.595436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4171</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.343415</td>\n",
              "      <td>0.423382</td>\n",
              "      <td>0.608520</td>\n",
              "      <td>0.118767</td>\n",
              "      <td>0.048236</td>\n",
              "      <td>0.537387</td>\n",
              "      <td>0.074718</td>\n",
              "      <td>0.334083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.551253</td>\n",
              "      <td>0.322684</td>\n",
              "      <td>-0.110489</td>\n",
              "      <td>0.280100</td>\n",
              "      <td>0.358211</td>\n",
              "      <td>0.313290</td>\n",
              "      <td>0.157374</td>\n",
              "      <td>0.024243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.634389</td>\n",
              "      <td>0.675127</td>\n",
              "      <td>1.567199</td>\n",
              "      <td>0.708957</td>\n",
              "      <td>0.746803</td>\n",
              "      <td>0.981006</td>\n",
              "      <td>0.498780</td>\n",
              "      <td>-0.285597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.842227</td>\n",
              "      <td>0.775825</td>\n",
              "      <td>0.249015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.771511</td>\n",
              "      <td>0.738616</td>\n",
              "      <td>0.412530</td>\n",
              "      <td>0.024243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.548877</td>\n",
              "      <td>1.480712</td>\n",
              "      <td>1.327529</td>\n",
              "      <td>2.286541</td>\n",
              "      <td>2.633606</td>\n",
              "      <td>1.795070</td>\n",
              "      <td>1.842840</td>\n",
              "      <td>0.643923</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4176 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      type    length     width    height  total_weight  meat_weight  \\\n",
              "0      NaN -1.443993 -1.439534 -1.189003     -1.232135    -1.166955   \n",
              "1      NaN  0.052442  0.121288 -0.110489     -0.310090    -0.461650   \n",
              "2      NaN -0.695776 -0.432552 -0.350159     -0.638881    -0.645838   \n",
              "3      NaN       NaN -1.540232 -1.428673     -1.273999    -1.211879   \n",
              "4      NaN -0.820479 -1.087090 -1.069168     -0.974820    -0.980521   \n",
              "...    ...       ...       ...       ...           ...          ...   \n",
              "4171   NaN  0.343415  0.423382  0.608520      0.118767     0.048236   \n",
              "4172   NaN  0.551253  0.322684 -0.110489      0.280100     0.358211   \n",
              "4173   NaN  0.634389  0.675127  1.567199      0.708957     0.746803   \n",
              "4174   NaN  0.842227  0.775825  0.249015           NaN     0.771511   \n",
              "4175   NaN  1.548877  1.480712  1.327529      2.286541     2.633606   \n",
              "\n",
              "      drained_weight  shell_weight  num_rings  \n",
              "0          -1.205076     -1.211842        NaN  \n",
              "1          -0.354425     -0.205594  -0.285597  \n",
              "2          -0.605962     -0.600906   0.024243  \n",
              "3          -1.287397     -1.319655  -0.905276  \n",
              "4          -0.939820     -0.852468  -0.595436  \n",
              "...              ...           ...        ...  \n",
              "4171        0.537387      0.074718   0.334083  \n",
              "4172        0.313290      0.157374   0.024243  \n",
              "4173        0.981006      0.498780  -0.285597  \n",
              "4174        0.738616      0.412530   0.024243  \n",
              "4175        1.795070      1.842840   0.643923  \n",
              "\n",
              "[4176 rows x 9 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##################(\n",
        "standard_derivation = data_nomissing.std()\n",
        "Z_score = (data_nomissing[df.columns[1:]] - mean) / standard_derivation\n",
        "\n",
        "Z_score = Z_score[df.columns]\n",
        "Z_score\n",
        "##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krOpdi_i1o5J"
      },
      "source": [
        "## 2. Preprocessing text (Optional)\n",
        "\n",
        "One possible way to transform text documents into vectors of numeric attributes is to use the TF-IDF representation. We will experiment with this representation using the 20 Newsgroup data set. The data set contains postings on 20 different topics. The classification problem is to decide which of the topics a posting falls into. Here, we will only consider postings about medicine and space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TmhZ8_FC1o5J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The index of each category is: [(0, 'sci.med'), (1, 'sci.space')]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "categories = ['sci.med', 'sci.space']\n",
        "raw_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "print(f'The index of each category is: {[(i,target) for i,target in enumerate(raw_data.target_names)]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kWdpZz61o5K"
      },
      "source": [
        "Check out some of the postings, might find some funny ones!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CFZgvye31o5K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a sci.space email.\n",
            "\n",
            "There are 1187 emails.\n",
            "\n",
            "From: aws@iti.org (Allen W. Sherzer)\n",
            "Subject: Re: Why not give $1 billion to first year-long moon residents?\n",
            "Organization: Evil Geniuses for a Better Tomorrow\n",
            "Lines: 34\n",
            "\n",
            "In article <C5sJDp.F23@zoo.toronto.edu> henry@zoo.toronto.edu (Henry Spencer) writes:\n",
            "\n",
            ">>This prize isn't big enough to warrent developing a SSTO, but it is\n",
            ">>enough to do it if the vehicle exists.\n",
            "\n",
            ">Actually, there are people who will tell you that it *would* be enough\n",
            ">to do SSTO development, if done privately as a cut-rate operation.  Of\n",
            ">course, they may be over-optimistic.\n",
            "\n",
            "In spite of my great respect for the people you speak of, I think their\n",
            "cost estimates are a bit over-optimistic. If nothing else, a working SSTO\n",
            "is at least as complex as a large airliner and has a smaller experience\n",
            "base. It therefore seems that SSTO development should cost at least as\n",
            "much as a typical airliner development. That puts it in the $3G to $5G\n",
            "range.\n",
            "\n",
            ">You can also assume that a working SSTO would have other applications\n",
            ">that would help pay for its development costs.\n",
            "\n",
            "True it and the contest would result in a much larger market. But I\n",
            "don't think it would be enough to attract the investors given the\n",
            "risks involved.\n",
            "\n",
            "If you could gurantee the SSTO costs and gurantee that it captures\n",
            "100% of the available launch market, then I think you could\n",
            "do it.\n",
            "\n",
            "  Allen\n",
            "\n",
            "-- \n",
            "+---------------------------------------------------------------------------+\n",
            "| Lady Astor:   \"Sir, if you were my husband I would poison your coffee!\"   |\n",
            "| W. Churchill: \"Madam, if you were my wife, I would drink it.\"             |\n",
            "+----------------------56 DAYS TO FIRST FLIGHT OF DCX-----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "idx = np.random.randint(0, len(raw_data.data))\n",
        "print (f'This is a {raw_data.target_names[raw_data.target[idx]]} email.\\n')\n",
        "print (f'There are {len(raw_data.data)} emails.\\n')\n",
        "print(raw_data.data[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytNRgBtD1o5L"
      },
      "source": [
        "Lets pick the first 10 postings from each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7XjYd0ML1o5L"
      },
      "outputs": [],
      "source": [
        "idxs_med = np.flatnonzero(raw_data.target == 0)\n",
        "idxs_space = np.flatnonzero(raw_data.target == 1)\n",
        "idxs = np.concatenate([idxs_med[:10],idxs_space[:10]])\n",
        "data = np.array(raw_data.data)\n",
        "data = data[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY4YffVy1o5M"
      },
      "source": [
        "<a href=\"http://www.nltk.org/\">NLTK</a> is a toolkit for natural language processing. Take some time to install it and go through this <a href=\"http://www.slideshare.net/japerk/nltk-in-20-minutes\">short tutorial/presentation</a>. (or use e.g. Google colab where the package is prepared already)\n",
        "\n",
        "The downloaded package below is a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\juand\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GhpnijnB1o5M"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import itertools\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in data]\n",
        "vocabulary_size = 1000\n",
        "unknown_token = 'unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "LvKCOBjx1o5M"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1632 unique words tokens.\n"
          ]
        }
      ],
      "source": [
        "# Count the word frequencies\n",
        "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
        "print (f\"Found {len(word_freq.items())} unique words tokens.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yw_h_8Vo1o5N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using vocabulary size 1000.\n",
            "The least frequent word in our vocabulary is 'NEEDS' and appeared 1 times.\n"
          ]
        }
      ],
      "source": [
        "# Get the most common words and build index_to_word and word_to_index vectors\n",
        "vocab = word_freq.most_common(vocabulary_size-1)\n",
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
        " \n",
        "print (f\"Using vocabulary size {vocabulary_size}.\" )\n",
        "print (f\"The least frequent word in our vocabulary is '{vocab[-1][0]}' and appeared {vocab[-1][1]} times.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CxBYzBs1o5N"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "Code your own TF-IDF representation function and use it on this dataset. (Don't use code from libraries. Build your own function with Numpy/Pandas). Use the formular TFIDF = TF * (IDF+1). The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. The term frequency is the raw count of a term in a document. The inverse document frequency is the natural logarithm of the inverse fraction of the documents that contain the word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LAQX0zw11o5N"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is this implementation correct?\n",
            "Answer: No\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "countvec = CountVectorizer()\n",
        "df = pd.DataFrame(countvec.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
        "\n",
        "def tfidf(df):\n",
        "    \n",
        "    ##################\n",
        "    #INSERT CODE HERE#\n",
        "    ##################\n",
        "    return None\n",
        "    \n",
        "    \n",
        "rep = tfidf(df)\n",
        "\n",
        "# Check if your implementation is correct\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False, use_idf=True)\n",
        "X_train = pd.DataFrame(vectorizer.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
        "answer=['No','Yes']\n",
        "epsilon = 0.0001\n",
        "if rep is None: \n",
        "  print (f'Is this implementation correct?\\nAnswer: {answer[0]}')\n",
        "if rep is not None:\n",
        "  print (f'Is this implementation correct?\\nAnswer: {answer[1*np.all((X_train - rep) < epsilon)]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvgshAez8XY2"
      },
      "outputs": [],
      "source": [
        "# an example of what to do with these similarities:\n",
        "\n",
        "\n",
        "# analysis with tf-idf\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similiarities = cosine_similarity(rep, rep) # measure of the similarity of the direction of two vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39RjLr9J8b8f"
      },
      "outputs": [],
      "source": [
        "np.fill_diagonal(similiarities, 0)\n",
        "max_ind = np.unravel_index(similiarities.argmax(), similiarities.shape)\n",
        "similiarities[max_ind] # highest similarity of two documents"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Problem_Analysis_and_Data_Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
